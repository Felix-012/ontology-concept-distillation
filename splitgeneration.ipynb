{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to generate all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atelectasis         10029\n",
       "Cardiomegaly        10614\n",
       "Consolidation        1689\n",
       "Edema                4966\n",
       "No Finding          69677\n",
       "Pleural Effusion     9301\n",
       "Pneumonia            5385\n",
       "Pneumothorax         3412\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "BASEDIR_MIMIC = \"../data/mimic/\"\n",
    "# Set up plotting style\n",
    "# Load preprocessed metadata\n",
    "metadata_df = pd.read_csv(os.path.join(BASEDIR_MIMIC,'mimic_metadata_preprocessed.csv'))\n",
    "# Get numerical columns (excluding subject_id, study_id etc)\n",
    "numerical_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n",
    "                 'No Finding', 'Pleural Effusion',\n",
    "                 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "\n",
    "\n",
    "#columns_of_interest = [\"No Finding\", \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Pleural Effusion\", \"Pneumonia\", \"Pneumothorax\"] #\"No Finding\" is first column\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# Convert numerical values to boolean True/False\n",
    "# True for positive cases (1.0), False otherwise\n",
    "metadata_df[numerical_cols] = metadata_df[numerical_cols].apply(lambda x: x == 1.0)\n",
    "label_cols = numerical_cols\n",
    "# removed all entries with more than one label\n",
    "metadata_df = metadata_df[metadata_df[label_cols].sum(axis=1) == 1]\n",
    "\n",
    "#metadata_df = metadata_df[metadata_df[\"Pleural Other\"] == False]\n",
    "metadata_df[label_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 105115\n",
      "Test set size: 1600\n",
      "\n",
      "Test set label distribution:\n",
      "Atelectasis         200\n",
      "Cardiomegaly        200\n",
      "Consolidation       200\n",
      "Edema               200\n",
      "No Finding          200\n",
      "Pleural Effusion    200\n",
      "Pneumonia           200\n",
      "Pneumothorax        200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create balanced test set with 283 images per class\n",
    "test_size = 200 \n",
    "\n",
    "# Initialize empty list to store test indices\n",
    "test_indices = []\n",
    "\n",
    "# For each label, randomly sample test_size images\n",
    "for label in label_cols:\n",
    "    # Get indices of positive cases for this label\n",
    "    label_indices = metadata_df[metadata_df[label]].index.tolist()\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(1)\n",
    "    # Randomly sample test_size indices\n",
    "    sampled_indices = np.random.choice(label_indices, size=test_size, replace=False)\n",
    "    \n",
    "    test_indices.extend(sampled_indices)\n",
    "\n",
    "# Convert to array and get unique indices (in case of any overlap)\n",
    "test_indices = np.unique(test_indices)\n",
    "\n",
    "# Create test dataframe\n",
    "test_df = metadata_df.loc[test_indices]\n",
    "\n",
    "# Create train dataframe by removing test subjects\n",
    "train_subjects = set(metadata_df['subject_id']) - set(test_df['subject_id'])\n",
    "train_df = metadata_df[metadata_df['subject_id'].isin(train_subjects)]\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(\"\\nTest set label distribution:\")\n",
    "print(test_df[label_cols].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 93063\n",
      "retrieve set size: 2400\n",
      "\n",
      "Retrieve set label distribution:\n",
      "Atelectasis         300\n",
      "Cardiomegaly        300\n",
      "Consolidation       300\n",
      "Edema               300\n",
      "No Finding          300\n",
      "Pleural Effusion    300\n",
      "Pneumonia           300\n",
      "Pneumothorax        300\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Atelectasis          7700\n",
       "Cardiomegaly         7880\n",
       "Consolidation         706\n",
       "Edema                3227\n",
       "No Finding          61820\n",
       "Pleural Effusion     6489\n",
       "Pneumonia            3846\n",
       "Pneumothorax         1395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create balanced test set with 283 images per class\n",
    "retrieve_size = 300 \n",
    "\n",
    "# Initialize empty list to store test indices\n",
    "retrieve_indices = []\n",
    "\n",
    "# For each label, randomly sample retrieve_size images\n",
    "for label in label_cols:\n",
    "    # Get indices of positive cases for this label\n",
    "    label_indices = train_df[train_df[label]].index.tolist()\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(1)\n",
    "    # Randomly sample retrieve_size indices\n",
    "    sampled_indices = np.random.choice(label_indices, size=retrieve_size, replace=False)\n",
    "    \n",
    "    retrieve_indices.extend(sampled_indices)\n",
    "\n",
    "# Convert to array and get unique indices (in case of any overlap)\n",
    "retrieve_indices = np.unique(retrieve_indices)\n",
    "\n",
    "# Create retrieve dataframe\n",
    "retrieve_df = train_df.loc[retrieve_indices]\n",
    "\n",
    "# Create train dataframe by removing retrieve subjects\n",
    "retrieve_subjects = set(train_df['subject_id']) - set(retrieve_df['subject_id']) - set(test_df[\"subject_id\"])\n",
    "train_df = train_df[train_df['subject_id'].isin(retrieve_subjects)]\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"retrieve set size: {len(retrieve_df)}\")\n",
    "print(\"\\nRetrieve set label distribution:\")\n",
    "print(retrieve_df[label_cols].sum())\n",
    "train_df[label_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_empty_intersect(set_a, set_b): \n",
    "    assert len(set_a.intersection(set_b) ) == 0\n",
    "\n",
    "assert_empty_intersect(set(test_df[\"subject_id\"]),  set(train_df[\"subject_id\"]))\n",
    "assert_empty_intersect(set(test_df[\"subject_id\"]),  set(retrieve_df[\"subject_id\"]))\n",
    "assert_empty_intersect(set(train_df[\"subject_id\"]), set(retrieve_df[\"subject_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atelectasis         706\n",
       "Cardiomegaly        706\n",
       "Consolidation       706\n",
       "Edema               706\n",
       "No Finding          706\n",
       "Pleural Effusion    706\n",
       "Pneumonia           706\n",
       "Pneumothorax        706\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create balanced test set with 283 images per class\n",
    "balanced_train_size = 706 \n",
    "\n",
    "# Initialize empty list to store test indices\n",
    "retrieve_indices = []\n",
    "\n",
    "# For each label, randomly sample balanced_train_size images\n",
    "for label in label_cols:\n",
    "    # Get indices of positive cases for this label\n",
    "    label_indices = train_df[train_df[label]].index.tolist()\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(1)\n",
    "    # Randomly sample balanced_train_size indices\n",
    "    sampled_indices = np.random.choice(label_indices, size=balanced_train_size, replace=False)\n",
    "    \n",
    "    retrieve_indices.extend(sampled_indices)\n",
    "\n",
    "# Convert to array and get unique indices (in case of any overlap)\n",
    "retrieve_indices = np.unique(retrieve_indices)\n",
    "\n",
    "# Create retrieve dataframe\n",
    "train_balanced_df = train_df.loc[retrieve_indices]\n",
    "\n",
    "train_balanced_df[label_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atelectasis          7700\n",
       "Cardiomegaly         7880\n",
       "Consolidation         706\n",
       "Edema                3227\n",
       "No Finding          61820\n",
       "Pleural Effusion     6489\n",
       "Pneumonia            3846\n",
       "Pneumothorax         1395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[label_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframes to CSV files\n",
    "train_balanced_df.to_csv(os.path.join(BASEDIR_MIMIC, 'longtail_8_balanced_train.csv'), index=False)\n",
    "train_df.to_csv(os.path.join(BASEDIR_MIMIC, 'longtail_8_train.csv'), index=False)\n",
    "retrieve_df.to_csv(os.path.join(BASEDIR_MIMIC, 'longtail_8_balanced_retrieve.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(BASEDIR_MIMIC,'longtail_8_balanced_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease counts in unbalanced training set:\n",
      "Atelectasis         706\n",
      "Cardiomegaly        706\n",
      "Consolidation        10\n",
      "Edema               706\n",
      "No Finding          706\n",
      "Pleural Effusion    706\n",
      "Pneumonia           706\n",
      "Pneumothorax        706\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create unbalanced train set with only 10 consolidation samples\n",
    "disease_to_undersample = \"Consolidation\"\n",
    "consolidation_indices = train_balanced_df[train_balanced_df[disease_to_undersample] == True].index.tolist()\n",
    "np.random.seed(1)\n",
    "sampled_consolidation = np.random.choice(consolidation_indices, size=10, replace=False)\n",
    "\n",
    "# Get all non-consolidation samples\n",
    "non_consolidation_indices = train_balanced_df[~train_balanced_df.index.isin(consolidation_indices)].index.tolist()\n",
    "\n",
    "# Combine indices and create new dataframe\n",
    "train_df_unbalanced = train_balanced_df.loc[non_consolidation_indices + list(sampled_consolidation)]\n",
    "\n",
    "# Verify counts\n",
    "print(\"Disease counts in unbalanced training set:\")\n",
    "print(train_df_unbalanced[label_cols].sum())\n",
    "\n",
    "# Export to CSV\n",
    "train_df_unbalanced.to_csv(os.path.join(BASEDIR_MIMIC, f'longtail_8_train_unbalanced_{disease_to_undersample}.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longtail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
